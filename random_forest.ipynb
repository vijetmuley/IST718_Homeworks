{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load these packages\n",
    "import pyspark\n",
    "from pyspark.ml import feature, classification\n",
    "from pyspark.ml import Pipeline, pipeline\n",
    "from pyspark.sql import functions as fn\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "import matplotlib.pyplot as plt\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze the Mid-atlantic wage dataset (https://rdrr.io/cran/ISLR/man/Wage.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "13b497143a441ab980a4d0df52131055",
     "grade": false,
     "grade_id": "cell-3969fb69476d2b82",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- maritl: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- jobclass: string (nullable = true)\n",
      " |-- health: string (nullable = true)\n",
      " |-- health_ins: string (nullable = true)\n",
      " |-- wage: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read-only\n",
    "drop_cols = ['_c0', 'logwage', 'sex', 'region']\n",
    "wage_df = spark.read.csv('/datasets/ISLR/Wage.csv', header=True, inferSchema=True).drop(*drop_cols)\n",
    "training_df, validation_df, testing_df = wage_df.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "wage_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>maritl</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>jobclass</th>\n",
       "      <th>health</th>\n",
       "      <th>health_ins</th>\n",
       "      <th>wage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>18</td>\n",
       "      <td>1. Never Married</td>\n",
       "      <td>1. White</td>\n",
       "      <td>1. &lt; HS Grad</td>\n",
       "      <td>1. Industrial</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>2. No</td>\n",
       "      <td>75.043154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>24</td>\n",
       "      <td>1. Never Married</td>\n",
       "      <td>1. White</td>\n",
       "      <td>4. College Grad</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>2. No</td>\n",
       "      <td>70.476020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>45</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>1. White</td>\n",
       "      <td>3. Some College</td>\n",
       "      <td>1. Industrial</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>130.982177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>43</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>3. Asian</td>\n",
       "      <td>4. College Grad</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>154.685293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>50</td>\n",
       "      <td>4. Divorced</td>\n",
       "      <td>1. White</td>\n",
       "      <td>2. HS Grad</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>75.043154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008</td>\n",
       "      <td>54</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>1. White</td>\n",
       "      <td>4. College Grad</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>127.115744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009</td>\n",
       "      <td>44</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>4. Other</td>\n",
       "      <td>3. Some College</td>\n",
       "      <td>1. Industrial</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>169.528538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>30</td>\n",
       "      <td>1. Never Married</td>\n",
       "      <td>3. Asian</td>\n",
       "      <td>3. Some College</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>111.720849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2006</td>\n",
       "      <td>41</td>\n",
       "      <td>1. Never Married</td>\n",
       "      <td>2. Black</td>\n",
       "      <td>3. Some College</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>118.884359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2004</td>\n",
       "      <td>52</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>1. White</td>\n",
       "      <td>2. HS Grad</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>128.680488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  age            maritl      race        education        jobclass  \\\n",
       "0  2006   18  1. Never Married  1. White     1. < HS Grad   1. Industrial   \n",
       "1  2004   24  1. Never Married  1. White  4. College Grad  2. Information   \n",
       "2  2003   45        2. Married  1. White  3. Some College   1. Industrial   \n",
       "3  2003   43        2. Married  3. Asian  4. College Grad  2. Information   \n",
       "4  2005   50       4. Divorced  1. White       2. HS Grad  2. Information   \n",
       "5  2008   54        2. Married  1. White  4. College Grad  2. Information   \n",
       "6  2009   44        2. Married  4. Other  3. Some College   1. Industrial   \n",
       "7  2008   30  1. Never Married  3. Asian  3. Some College  2. Information   \n",
       "8  2006   41  1. Never Married  2. Black  3. Some College  2. Information   \n",
       "9  2004   52        2. Married  1. White       2. HS Grad  2. Information   \n",
       "\n",
       "           health health_ins        wage  \n",
       "0       1. <=Good      2. No   75.043154  \n",
       "1  2. >=Very Good      2. No   70.476020  \n",
       "2       1. <=Good     1. Yes  130.982177  \n",
       "3  2. >=Very Good     1. Yes  154.685293  \n",
       "4       1. <=Good     1. Yes   75.043154  \n",
       "5  2. >=Very Good     1. Yes  127.115744  \n",
       "6  2. >=Very Good     1. Yes  169.528538  \n",
       "7       1. <=Good     1. Yes  111.720849  \n",
       "8  2. >=Very Good     1. Yes  118.884359  \n",
       "9  2. >=Very Good     1. Yes  128.680488  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the data\n",
    "wage_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Codify the data using transformers (20 pts)\n",
    "\n",
    "Create a fitted pipeline to the entire data `wage_df` and call it `pipe_feat`. This pipeline should codify the columns `maritl`, `race`, `education`, `jobclass`, `health`, and `health_ins`. The codification should be a combination of a `StringIndexer` and a `OneHotEncoder`. For example, for `maritl`, `StringIndexer` should create a column `maritl_index` and `OneHotEncoder` should create a column `maritl_feat`. Investigate the parameters of `StringIndexer` so that the labels are indexed alphabetically in ascending order so that, for example, the 1st index for `maritl_index` corresponds to `1. Never Married`, the 2nd index corresponds to `2. Married`, and so forth. Also, investigate the parameters of  `OneHotEncoder` so that there are no columns dropped as it is usually done for dummy variables. This is, marital status should have one column for each of the classes.\n",
    "\n",
    "The pipeline should create a column `features` that combines `year`, `age`, and all codified columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b6f4272b29b08b91879e9ceff83ffde9",
     "grade": false,
     "grade_id": "cell-06ca40bbc2363d61",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'age', 'health_index', 'education_index', 'health_ins_index', 'race_index', 'jobclass_index', 'maritl_index', 'health_feat', 'education_feat', 'health_ins_feat', 'race_feat', 'jobclass_feat', 'maritl_feat']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>maritl</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>jobclass</th>\n",
       "      <th>health</th>\n",
       "      <th>health_ins</th>\n",
       "      <th>wage</th>\n",
       "      <th>health_index</th>\n",
       "      <th>...</th>\n",
       "      <th>race_index</th>\n",
       "      <th>jobclass_index</th>\n",
       "      <th>maritl_index</th>\n",
       "      <th>health_feat</th>\n",
       "      <th>education_feat</th>\n",
       "      <th>health_ins_feat</th>\n",
       "      <th>race_feat</th>\n",
       "      <th>jobclass_feat</th>\n",
       "      <th>maritl_feat</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>18</td>\n",
       "      <td>1. Never Married</td>\n",
       "      <td>1. White</td>\n",
       "      <td>1. &lt; HS Grad</td>\n",
       "      <td>1. Industrial</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>2. No</td>\n",
       "      <td>75.043154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>(2006.0, 18.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>24</td>\n",
       "      <td>1. Never Married</td>\n",
       "      <td>1. White</td>\n",
       "      <td>4. College Grad</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>2. No</td>\n",
       "      <td>70.476020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>(2004.0, 24.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>45</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>1. White</td>\n",
       "      <td>3. Some College</td>\n",
       "      <td>1. Industrial</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>130.982177</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>(2003.0, 45.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>43</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>3. Asian</td>\n",
       "      <td>4. College Grad</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>154.685293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>(2003.0, 43.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>50</td>\n",
       "      <td>4. Divorced</td>\n",
       "      <td>1. White</td>\n",
       "      <td>2. HS Grad</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>75.043154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0)</td>\n",
       "      <td>(2005.0, 50.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  age            maritl      race        education        jobclass  \\\n",
       "0  2006   18  1. Never Married  1. White     1. < HS Grad   1. Industrial   \n",
       "1  2004   24  1. Never Married  1. White  4. College Grad  2. Information   \n",
       "2  2003   45        2. Married  1. White  3. Some College   1. Industrial   \n",
       "3  2003   43        2. Married  3. Asian  4. College Grad  2. Information   \n",
       "4  2005   50       4. Divorced  1. White       2. HS Grad  2. Information   \n",
       "\n",
       "           health health_ins        wage  health_index  \\\n",
       "0       1. <=Good      2. No   75.043154           1.0   \n",
       "1  2. >=Very Good      2. No   70.476020           0.0   \n",
       "2       1. <=Good     1. Yes  130.982177           1.0   \n",
       "3  2. >=Very Good     1. Yes  154.685293           0.0   \n",
       "4       1. <=Good     1. Yes   75.043154           1.0   \n",
       "\n",
       "                         ...                          race_index  \\\n",
       "0                        ...                                 0.0   \n",
       "1                        ...                                 0.0   \n",
       "2                        ...                                 0.0   \n",
       "3                        ...                                 2.0   \n",
       "4                        ...                                 0.0   \n",
       "\n",
       "   jobclass_index  maritl_index  health_feat        education_feat  \\\n",
       "0             0.0           1.0        (0.0)  (0.0, 0.0, 0.0, 0.0)   \n",
       "1             1.0           1.0        (1.0)  (0.0, 1.0, 0.0, 0.0)   \n",
       "2             0.0           0.0        (0.0)  (0.0, 0.0, 1.0, 0.0)   \n",
       "3             1.0           0.0        (1.0)  (0.0, 1.0, 0.0, 0.0)   \n",
       "4             1.0           2.0        (0.0)  (1.0, 0.0, 0.0, 0.0)   \n",
       "\n",
       "  health_ins_feat        race_feat jobclass_feat           maritl_feat  \\\n",
       "0           (0.0)  (1.0, 0.0, 0.0)         (1.0)  (0.0, 1.0, 0.0, 0.0)   \n",
       "1           (0.0)  (1.0, 0.0, 0.0)         (0.0)  (0.0, 1.0, 0.0, 0.0)   \n",
       "2           (1.0)  (1.0, 0.0, 0.0)         (1.0)  (1.0, 0.0, 0.0, 0.0)   \n",
       "3           (1.0)  (0.0, 0.0, 1.0)         (0.0)  (1.0, 0.0, 0.0, 0.0)   \n",
       "4           (1.0)  (1.0, 0.0, 0.0)         (0.0)  (0.0, 0.0, 1.0, 0.0)   \n",
       "\n",
       "                                            features  \n",
       "0  (2006.0, 18.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 0...  \n",
       "1  (2004.0, 24.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1...  \n",
       "2  (2003.0, 45.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "3  (2003.0, 43.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1...  \n",
       "4  (2005.0, 50.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create `pipe_feat` below\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#Taking the names of columns from the original dataframe 'wage_df' in the list cols and removing the numeric columns (year and age)\n",
    "# and the dependent variable (wage); one ot be predicted:\n",
    "cols=wage_df.toPandas().columns\n",
    "cols=list(set(cols)-set([\"year\",\"age\",\"wage\"]))\n",
    "\n",
    "#Making lists for StringIndexers and OneHotEncoders for every categorical column in the dataframe:\n",
    "string_indexer=[]\n",
    "one_hot=[]\n",
    "\n",
    "#Making lists for the columns names associated with every StringIndexer and OneHotEncoder\n",
    "#Eg: Columns 'maritl' would have output column for StringIndexer as 'maritl_index' and OneHotEncoder output as 'maritl_feat':\n",
    "feats_index=[]\n",
    "feats_feat=[]\n",
    "\n",
    "#Running a loop over all the columns and making StringIndexer, OneHotEncoder models for each column and also taking the eventual\n",
    "#clumn names for making a dataframe ahead:\n",
    "for col in cols:\n",
    "    string_indexer.append(feature.StringIndexer(inputCol=col,outputCol=col+\"_index\"))\n",
    "    one_hot.append(feature.OneHotEncoder(inputCol=col+\"_index\",outputCol=col+\"_feat\"))\n",
    "    feats_index.append(col+\"_index\")\n",
    "    feats_feat.append(col+\"_feat\")\n",
    "\n",
    "#Finally, I added columns year and age to the final columns list, as well as columsn from StringIndexer and OneHotEncoder:\n",
    "feats=[\"year\",\"age\"]+feats_index+feats_feat\n",
    "print(feats)\n",
    "\n",
    "#Since 'stages' in Pipeline takes argument as a list, making one list out of different lists I made earlier (one for StringIndexers\n",
    "#and one for OneHotEncoders for different columns). Also adding a final VectorAssembler at the end:\n",
    "pipe_stages=string_indexer+one_hot+[feature.VectorAssembler(inputCols=feats,outputCol=\"features\")]\n",
    "\n",
    "#Making the Pipeline and fitting it:\n",
    "pipe_feat=Pipeline(stages=pipe_stages).fit(wage_df)\n",
    "\n",
    "#Transforming data using the model from the pipeline fitting:\n",
    "trans_df=pipe_feat.transform(wage_df)\n",
    "\n",
    "#Taking a look at the dataframe thus made:\n",
    "trans_df.toPandas().head()\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2006</td>\n",
       "      <td>2004</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maritl</th>\n",
       "      <td>1. Never Married</td>\n",
       "      <td>1. Never Married</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>2. Married</td>\n",
       "      <td>4. Divorced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>1. White</td>\n",
       "      <td>1. White</td>\n",
       "      <td>1. White</td>\n",
       "      <td>3. Asian</td>\n",
       "      <td>1. White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>1. &lt; HS Grad</td>\n",
       "      <td>4. College Grad</td>\n",
       "      <td>3. Some College</td>\n",
       "      <td>4. College Grad</td>\n",
       "      <td>2. HS Grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobclass</th>\n",
       "      <td>1. Industrial</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>1. Industrial</td>\n",
       "      <td>2. Information</td>\n",
       "      <td>2. Information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "      <td>2. &gt;=Very Good</td>\n",
       "      <td>1. &lt;=Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_ins</th>\n",
       "      <td>2. No</td>\n",
       "      <td>2. No</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>1. Yes</td>\n",
       "      <td>1. Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wage</th>\n",
       "      <td>75.0432</td>\n",
       "      <td>70.476</td>\n",
       "      <td>130.982</td>\n",
       "      <td>154.685</td>\n",
       "      <td>75.0432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_index</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_index</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_ins_index</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_index</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobclass_index</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maritl_index</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_feat</th>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_feat</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_ins_feat</th>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_feat</th>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobclass_feat</th>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>(0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maritl_feat</th>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <td>(2006.0, 18.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 0...</td>\n",
       "      <td>(2004.0, 24.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1...</td>\n",
       "      <td>(2003.0, 45.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>(2003.0, 43.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1...</td>\n",
       "      <td>(2005.0, 50.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  0  \\\n",
       "year                                                           2006   \n",
       "age                                                              18   \n",
       "maritl                                             1. Never Married   \n",
       "race                                                       1. White   \n",
       "education                                              1. < HS Grad   \n",
       "jobclass                                              1. Industrial   \n",
       "health                                                    1. <=Good   \n",
       "health_ins                                                    2. No   \n",
       "wage                                                        75.0432   \n",
       "health_index                                                      1   \n",
       "education_index                                                   4   \n",
       "health_ins_index                                                  1   \n",
       "race_index                                                        0   \n",
       "jobclass_index                                                    0   \n",
       "maritl_index                                                      1   \n",
       "health_feat                                                   (0.0)   \n",
       "education_feat                                 (0.0, 0.0, 0.0, 0.0)   \n",
       "health_ins_feat                                               (0.0)   \n",
       "race_feat                                           (1.0, 0.0, 0.0)   \n",
       "jobclass_feat                                                 (1.0)   \n",
       "maritl_feat                                    (0.0, 1.0, 0.0, 0.0)   \n",
       "features          (2006.0, 18.0, 1.0, 4.0, 1.0, 0.0, 0.0, 1.0, 0...   \n",
       "\n",
       "                                                                  1  \\\n",
       "year                                                           2004   \n",
       "age                                                              24   \n",
       "maritl                                             1. Never Married   \n",
       "race                                                       1. White   \n",
       "education                                           4. College Grad   \n",
       "jobclass                                             2. Information   \n",
       "health                                               2. >=Very Good   \n",
       "health_ins                                                    2. No   \n",
       "wage                                                         70.476   \n",
       "health_index                                                      0   \n",
       "education_index                                                   1   \n",
       "health_ins_index                                                  1   \n",
       "race_index                                                        0   \n",
       "jobclass_index                                                    1   \n",
       "maritl_index                                                      1   \n",
       "health_feat                                                   (1.0)   \n",
       "education_feat                                 (0.0, 1.0, 0.0, 0.0)   \n",
       "health_ins_feat                                               (0.0)   \n",
       "race_feat                                           (1.0, 0.0, 0.0)   \n",
       "jobclass_feat                                                 (0.0)   \n",
       "maritl_feat                                    (0.0, 1.0, 0.0, 0.0)   \n",
       "features          (2004.0, 24.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1...   \n",
       "\n",
       "                                                                  2  \\\n",
       "year                                                           2003   \n",
       "age                                                              45   \n",
       "maritl                                                   2. Married   \n",
       "race                                                       1. White   \n",
       "education                                           3. Some College   \n",
       "jobclass                                              1. Industrial   \n",
       "health                                                    1. <=Good   \n",
       "health_ins                                                   1. Yes   \n",
       "wage                                                        130.982   \n",
       "health_index                                                      1   \n",
       "education_index                                                   2   \n",
       "health_ins_index                                                  0   \n",
       "race_index                                                        0   \n",
       "jobclass_index                                                    0   \n",
       "maritl_index                                                      0   \n",
       "health_feat                                                   (0.0)   \n",
       "education_feat                                 (0.0, 0.0, 1.0, 0.0)   \n",
       "health_ins_feat                                               (1.0)   \n",
       "race_feat                                           (1.0, 0.0, 0.0)   \n",
       "jobclass_feat                                                 (1.0)   \n",
       "maritl_feat                                    (1.0, 0.0, 0.0, 0.0)   \n",
       "features          (2003.0, 45.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "\n",
       "                                                                  3  \\\n",
       "year                                                           2003   \n",
       "age                                                              43   \n",
       "maritl                                                   2. Married   \n",
       "race                                                       3. Asian   \n",
       "education                                           4. College Grad   \n",
       "jobclass                                             2. Information   \n",
       "health                                               2. >=Very Good   \n",
       "health_ins                                                   1. Yes   \n",
       "wage                                                        154.685   \n",
       "health_index                                                      0   \n",
       "education_index                                                   1   \n",
       "health_ins_index                                                  0   \n",
       "race_index                                                        2   \n",
       "jobclass_index                                                    1   \n",
       "maritl_index                                                      0   \n",
       "health_feat                                                   (1.0)   \n",
       "education_feat                                 (0.0, 1.0, 0.0, 0.0)   \n",
       "health_ins_feat                                               (1.0)   \n",
       "race_feat                                           (0.0, 0.0, 1.0)   \n",
       "jobclass_feat                                                 (0.0)   \n",
       "maritl_feat                                    (1.0, 0.0, 0.0, 0.0)   \n",
       "features          (2003.0, 43.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1...   \n",
       "\n",
       "                                                                  4  \n",
       "year                                                           2005  \n",
       "age                                                              50  \n",
       "maritl                                                  4. Divorced  \n",
       "race                                                       1. White  \n",
       "education                                                2. HS Grad  \n",
       "jobclass                                             2. Information  \n",
       "health                                                    1. <=Good  \n",
       "health_ins                                                   1. Yes  \n",
       "wage                                                        75.0432  \n",
       "health_index                                                      1  \n",
       "education_index                                                   0  \n",
       "health_ins_index                                                  0  \n",
       "race_index                                                        0  \n",
       "jobclass_index                                                    1  \n",
       "maritl_index                                                      2  \n",
       "health_feat                                                   (0.0)  \n",
       "education_feat                                 (1.0, 0.0, 0.0, 0.0)  \n",
       "health_ins_feat                                               (1.0)  \n",
       "race_feat                                           (1.0, 0.0, 0.0)  \n",
       "jobclass_feat                                                 (0.0)  \n",
       "maritl_feat                                    (0.0, 0.0, 1.0, 0.0)  \n",
       "features          (2005.0, 50.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate the results\n",
    "pipe_feat.transform(wage_df).limit(5).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c5fa22305ca72ca8f8009792f166f24d",
     "grade": true,
     "grade_id": "cell-f021fdae60597e9f",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (20 pts)\n",
    "assert set(type(pm) for pm in pipe_feat.stages) == {feature.OneHotEncoder, feature.StringIndexerModel, feature.VectorAssembler}\n",
    "assert len(pipe_feat.transform(wage_df).first().features) == 22\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: (15 pts)\n",
    "\n",
    "Create three pipelines that contain three different random forest regressions that take in all features from the `wage_df` to predict `wage`. These pipelines should have as first stage the pipeline created in question 1 and should be fitted to the training data.\n",
    "\n",
    "- `pipe_rf1`: Random forest with `maxDepth=1` and `numTrees=60`\n",
    "- `pipe_rf2`: Random forest with `maxDepth=3` and `numTrees=40`\n",
    "- `pipe_rf3`: Random forest with `maxDepth=6`, `numTrees=20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "937fda91b6f78f26ff1cefcb0f4766f3",
     "grade": false,
     "grade_id": "cell-81a05842530a4bf5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create the fitted pipelines `pipe_rf1`, `pipe_rf2`, and `pipe_rf3` here\n",
    "# YOUR CODE HERE\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "#Using the pipe_feat made previously, I made 3 pipelines that used that pipeline and used the output from that pipeline as \n",
    "#an input for the random forest regressor model. I am using different parameters that the professor asked. The pipelines \n",
    "#are fit upon the training_df, which is 60% of the original data:\n",
    "\n",
    "#The labelCol is the dependent variable columns, in my case the 'wage' column:\n",
    "\n",
    "random_forest_1=RandomForestRegressor(featuresCol=\"features\",labelCol=\"wage\",maxDepth=1,numTrees=60)\n",
    "pipe_rf1=Pipeline(stages=[pipe_feat,random_forest_1]).fit(training_df)\n",
    "\n",
    "random_forest_2=RandomForestRegressor(featuresCol=\"features\",labelCol=\"wage\",maxDepth=3,numTrees=40)\n",
    "pipe_rf2=Pipeline(stages=[pipe_feat,random_forest_2]).fit(training_df)\n",
    "\n",
    "random_forest_3=RandomForestRegressor(featuresCol=\"features\",labelCol=\"wage\",maxDepth=6,numTrees=20)\n",
    "pipe_rf3=Pipeline(stages=[pipe_feat,random_forest_3]).fit(training_df)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "918062cd396f3a9c3ebda974d405802c",
     "grade": true,
     "grade_id": "cell-af70c6d07ebf40ef",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 15 pts\n",
    "np.testing.assert_equal(type(pipe_rf1.stages[0]), pipeline.PipelineModel)\n",
    "np.testing.assert_equal(type(pipe_rf2.stages[0]), pipeline.PipelineModel)\n",
    "np.testing.assert_equal(type(pipe_rf3.stages[0]), pipeline.PipelineModel)\n",
    "np.testing.assert_equal(type(pipe_rf1.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf2.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf3.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf1.transform(training_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(type(pipe_rf2.transform(training_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(type(pipe_rf3.transform(training_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (10 pts)\n",
    "\n",
    "Use the following evaluator to compute the RMSE of the models on validation data. Print the RMSE of the three models and assign the best one (i.e., the best pipeline) to a variable `best_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "73cc7671f0711e342716e8875324b1ca",
     "grade": false,
     "grade_id": "cell-1f8bd4cfa96e326a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "evaluator = evaluation.RegressionEvaluator(labelCol='wage', metricName='rmse')\n",
    "# use it as follows:\n",
    "#   evaluator.evaluate(fitted_pipeline.transform(df)) -> RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3c21368329ee32c72847a9261925e586",
     "grade": false,
     "grade_id": "cell-2e53b6ab6e82f38d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error for pipe_rf1: 36.214626318832885\n",
      "Root Mean Square Error for pipe_rf2: 33.56759433852202\n",
      "Root Mean Square Error for pipe_rf3: 33.241366680095744\n"
     ]
    }
   ],
   "source": [
    "# print MSE of each model and define `best_model`\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#Evaluating RMSE for the 3 models made on the validation_df (30% of the original data, exclusive of the training_df):\n",
    "\n",
    "RMSE1=evaluator.evaluate(pipe_rf1.transform(validation_df))\n",
    "RMSE2=evaluator.evaluate(pipe_rf2.transform(validation_df))\n",
    "RMSE3=evaluator.evaluate(pipe_rf3.transform(validation_df))\n",
    "\n",
    "print(\"Root Mean Square Error for pipe_rf1: \"+str(RMSE1))\n",
    "print(\"Root Mean Square Error for pipe_rf2: \"+str(RMSE2))\n",
    "print(\"Root Mean Square Error for pipe_rf3: \"+str(RMSE3))\n",
    "\n",
    "#The model with the lowest RMSE is assigned to 'best_model':\n",
    "if RMSE1==min(RMSE1,RMSE2,RMSE3):\n",
    "    best_model=pipe_rf1\n",
    "elif RMSE2==min(RMSE1,RMSE2,RMSE3):\n",
    "    best_model=pipe_rf2\n",
    "else:\n",
    "    best_model=pipe_rf3\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e626dc1e89241ad46546ac559e951ca7",
     "grade": true,
     "grade_id": "cell-c87098fdf26d5f77",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 10 pts\n",
    "np.testing.assert_equal(type(best_model.stages[0]), pipeline.PipelineModel)\n",
    "np.testing.assert_equal(type(best_model.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(best_model.transform(training_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: 5 pts\n",
    "\n",
    "Compute the RMSE of the model on testing data, print it, and assign it to variable `RMSE_best`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4f64d0e15006450b30465eba9c04809b",
     "grade": false,
     "grade_id": "cell-975307604e1c7a37",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create RMSE_best below\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#Taking the RMSE of the 'best_model' and assigning it to 'RMSE_best':\n",
    "RMSE_best=evaluator.evaluate(best_model.transform(testing_df))\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1352035aa1251f5f3dbdd1eaa97378d3",
     "grade": true,
     "grade_id": "cell-79c466e618817e90",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 5 pts\n",
    "np.testing.assert_array_less(RMSE_best, 40)\n",
    "np.testing.assert_array_less(30, RMSE_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: 5 pts\n",
    "\n",
    "Using the parameters of the best model, create a new pipeline called `final_model` and fit it to the entire data (`wage_df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f1029e0fa09318af8175fcdcd931eca9",
     "grade": false,
     "grade_id": "cell-6a682b3fdbb9ff9c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create final_model pipeline below\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#Using the parameters (stages) from the 'best_model' and making a pipeline first and then fitting that pipeline to the\n",
    "#whole 'wage_df'. This model is assigned to 'final_model':\n",
    "\n",
    "final_model=Pipeline(stages=[best_model.stages[0],best_model.stages[1]]).fit(wage_df)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "56d5b234a9fc45e110683dc01ae7dffa",
     "grade": true,
     "grade_id": "cell-803d8872aeb9cc8f",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 5 pts\n",
    "np.testing.assert_equal(type(final_model.stages[0]), pipeline.PipelineModel)\n",
    "np.testing.assert_equal(type(final_model.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(final_model.transform(wage_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6: 30 pts\n",
    "\n",
    "Create a pandas dataframe `feature_importance` with the columns `feature` and `importance` which contains the names of the features. Give appropriate column names such as `maritl_1._Never_Married`. You can build these feature names by using the labels from the fitted `StringIndexer` used in Question 1. Use as feature importance as determined by the random forest of the final model (`final_model`). Sort the pandas dataframe by `importance` in descending order and display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1f05a027040f4b4b04272173270dcc9b",
     "grade": false,
     "grade_id": "cell-0f7185f318626a45",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# create feature_importance below\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#So, I start with taking the first stage from the 'final_model' which is the 'pipe_feat' I made earlier:\n",
    "inner_pipeline=final_model.stages[0]\n",
    "\n",
    "#Taking names of all the columns from 'wage_df' and removing the numerical columns (year and age) and the dependent variable wage:\n",
    "cols=list(set(wage_df.columns)-set([\"wage\",\"year\",\"age\"]))\n",
    "\n",
    "#I made a empty list for all the column names that'd be used for the dataframe 'feature_importance' eventually:\n",
    "col_list=[]\n",
    "\n",
    "#From the 'pipe_feat' I extracted from 'final_model', I am reading all the stages (be it StringIndexer or OneHotEncoder or VectorAssembler)\n",
    "#I am working only with StringIndexers and taking the lables from the StringIndexers to have the columns that are used in\n",
    "#the random forest model. This makes a list of lists. The inner lists have labels corresponding to all possible classes\n",
    "#that particular categorical variable can be:\n",
    "for ele in inner_pipeline.stages:\n",
    "    if str(type(ele))==\"<class 'pyspark.ml.feature.StringIndexerModel'>\":\n",
    "        col_list.append(ele.labels)\n",
    "\n",
    "#Just checking the lengths, they are the same, they both have a length of 6:\n",
    "#print(len(col_list))\n",
    "#print(len(cols))\n",
    "\n",
    "#Now I know they are having a one to one relation, because they are two different ends of the same pipeline:\n",
    "i=0\n",
    "\n",
    "#I am taking the numeric columns in this list, that will have other columns. The other columns are from StingIndexer, \n",
    "#which did not have the numerical columns, so had to explicitly add them:\n",
    "col1=[\"year\",\"age\"]\n",
    "\n",
    "#I am reading the different lists inside the bigger list  (col_list). For every item inside the inner list (different categorical values\n",
    "#that particular column can take), I am making a string which starts with the column name and is followed by the categorical value for that label:\n",
    "for ls in col_list:\n",
    "    for item in ls:\n",
    "        col1.append((str(cols[i])+\" \"+str(item)).replace(\" \",\"_\"))\n",
    "    i=i+1\n",
    "\n",
    "#It is basically such that at the same index for both the lists, the 'cols' list has a column name and the list at the same\n",
    "#index in 'col_list' is a list of all possible categorical values that particular column can take. Finally, 'col1' will have\n",
    "#all feature names used in random forest the way it is asked.\n",
    "   \n",
    "#Then I am assigning the random forest model from the 'final_model' to 'rf_stage':\n",
    "rf_stage=final_model.stages[-1]\n",
    "\n",
    "#Taking the importance weights:\n",
    "weights=list(rf_stage.featureImportances.toArray())\n",
    "\n",
    "#Checking the length to make sure the columns list (col1; all the factors used in random forest) and the importance values\n",
    "#list is of the same length. They both have a length of 22:\n",
    "print(len(col1))\n",
    "print(len(weights))\n",
    "\n",
    "#Making a dataframe from those 2 lists, naming the columns as 'feature' and 'importance' and sorting the dataframe by 'importance'\n",
    "#values in a descending manner:\n",
    "feature_importance=pd.DataFrame(list(zip(col1,weights)),columns=[\"feature\",\"importance\"]).sort_values(\"importance\",ascending=False)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health_1._&lt;=Good</td>\n",
       "      <td>0.243577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>race_2._Black</td>\n",
       "      <td>0.170570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>0.110303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>education_2._HS_Grad</td>\n",
       "      <td>0.071034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>race_3._Asian</td>\n",
       "      <td>0.065522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>health_ins_2._No</td>\n",
       "      <td>0.058480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>maritl_1._Never_Married</td>\n",
       "      <td>0.044088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>maritl_4._Divorced</td>\n",
       "      <td>0.043712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>education_5._Advanced_Degree</td>\n",
       "      <td>0.040551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>year</td>\n",
       "      <td>0.032153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>health_ins_1._Yes</td>\n",
       "      <td>0.025705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>maritl_2._Married</td>\n",
       "      <td>0.017095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>race_1._White</td>\n",
       "      <td>0.015632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>health_2._&gt;=Very_Good</td>\n",
       "      <td>0.014250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>education_1._&lt;_HS_Grad</td>\n",
       "      <td>0.014064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>education_4._College_Grad</td>\n",
       "      <td>0.010438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>education_3._Some_College</td>\n",
       "      <td>0.009316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>race_4._Other</td>\n",
       "      <td>0.005125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>maritl_5._Separated</td>\n",
       "      <td>0.004145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jobclass_2._Information</td>\n",
       "      <td>0.002621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jobclass_1._Industrial</td>\n",
       "      <td>0.001418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>maritl_3._Widowed</td>\n",
       "      <td>0.000201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         feature  importance\n",
       "3               health_1._<=Good    0.243577\n",
       "12                 race_2._Black    0.170570\n",
       "1                            age    0.110303\n",
       "4           education_2._HS_Grad    0.071034\n",
       "13                 race_3._Asian    0.065522\n",
       "10              health_ins_2._No    0.058480\n",
       "18       maritl_1._Never_Married    0.044088\n",
       "19            maritl_4._Divorced    0.043712\n",
       "7   education_5._Advanced_Degree    0.040551\n",
       "0                           year    0.032153\n",
       "9              health_ins_1._Yes    0.025705\n",
       "17             maritl_2._Married    0.017095\n",
       "11                 race_1._White    0.015632\n",
       "2          health_2._>=Very_Good    0.014250\n",
       "8         education_1._<_HS_Grad    0.014064\n",
       "5      education_4._College_Grad    0.010438\n",
       "6      education_3._Some_College    0.009316\n",
       "14                 race_4._Other    0.005125\n",
       "20           maritl_5._Separated    0.004145\n",
       "16       jobclass_2._Information    0.002621\n",
       "15        jobclass_1._Industrial    0.001418\n",
       "21             maritl_3._Widowed    0.000201"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display your feature importances here\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "65a7424b40deec2e714bd3764fb56667",
     "grade": true,
     "grade_id": "cell-dc3926e469167f5e",
     "locked": true,
     "points": 25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 25 pts\n",
    "assert type(feature_importance) == pd.core.frame.DataFrame\n",
    "np.testing.assert_array_equal(list(feature_importance.columns), ['feature', 'importance'])\n",
    "np.testing.assert_array_equal(list(feature_importance.columns), ['feature', 'importance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5 pts)** Comment below on the importance that random forest has given to each feature. Are they reasonable? Do they tell you anything valuable about the titanic dataset? Answer in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "36878e68cb44923cdebab7fbd3f69660",
     "grade": true,
     "grade_id": "cell-21e30d00198bae80",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The importance values acquired from the random forest model tell us about the impact of the features on the outcome (in this case, prediciton of 'wage'). The value of importance weight is based upong the coefficient value in the regressor; bigger the coefficient, greater is the importance.\n",
    "\n",
    "However, it is to be noted that random forest model will average the importance for features over all the trees in the forest. That is, importance for, say age, will be average of importance of 'age' over all the trees in the model. The average values are also normalized to be in the range 0 to 1.\n",
    "\n",
    "From the feature_importance dataframe, it can be said that 'health_1.\\_<=Good' is the most important feature with the weight 0.243577 for the random forest model as a whole. These importance weights tell us about the intensity of impact on the prediction ('wage'), however, they do not tell us whether the features impact prediciton of 'wage' positively or negatively.\n",
    "\n",
    "P.S.: I have experienced that re-running the kernel and restarting the whole code will start at different starting points and thus everything changes, that is, the importance weights, the features having thos weights, the trees.\n",
    "This interpretation and answer is based upon the output that is a result of this execution instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7:  15 pts.\n",
    "\n",
    "Pick any of the trees from the final model and assign its `toDebugString` property to a variable `example_tree`. Print this variable and add comments to the cell describing how you think this particular tree is fitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a60948658565a5116e4b3e8bb7e602b4",
     "grade": false,
     "grade_id": "cell-bf4e4b6323d9fcb5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# create a variable example_tree with the toDebugString property of a tree from final_model.\n",
    "# print this string and comment in this same cell about the branches that this tree fit\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#I like the number 3, so I am assigning the tree with index 3 from my random forest model (4th tree from my model) to 'example_tree'\n",
    "#I used the rf_stage I made in the previous block of code:\n",
    "print(len(rf_stage.trees))\n",
    " \n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 0 -> year\n",
      "feature 1 -> age\n",
      "feature 2 -> health_2._>=Very_Good\n",
      "feature 3 -> health_1._<=Good\n",
      "feature 4 -> education_2._HS_Grad\n",
      "feature 5 -> education_4._College_Grad\n",
      "feature 6 -> education_3._Some_College\n",
      "feature 7 -> education_5._Advanced_Degree\n",
      "feature 8 -> education_1._<_HS_Grad\n",
      "feature 9 -> health_ins_1._Yes\n",
      "feature 10 -> health_ins_2._No\n",
      "feature 11 -> race_1._White\n",
      "feature 12 -> race_2._Black\n",
      "feature 13 -> race_3._Asian\n",
      "feature 14 -> race_4._Other\n",
      "feature 15 -> jobclass_1._Industrial\n",
      "feature 16 -> jobclass_2._Information\n",
      "feature 17 -> maritl_2._Married\n",
      "feature 18 -> maritl_1._Never_Married\n",
      "feature 19 -> maritl_4._Divorced\n",
      "feature 20 -> maritl_5._Separated\n",
      "feature 21 -> maritl_3._Widowed\n"
     ]
    }
   ],
   "source": [
    "#I wrote an extra block of code. Random forest regressor model does not show the actual name of feature used, but rather\n",
    "#shows up as 'feature {some number}'. So I wrote a code to map the label from model to the actual data labels:\n",
    "\n",
    "#Row labels for 'feature_importance' are actually the numbers that will be in front of 'feature' in the ranodm forest model\n",
    "#So I am taking the row labels (index) in a list:\n",
    "num=list(feature_importance.index)\n",
    "\n",
    "#Taking names of the actual features from the 'feature_importance' dataframe in another list. The row labels and name of feature\n",
    "#correspond when it comes to indices in these lists:\n",
    "feat=list(feature_importance[\"feature\"])\n",
    "\n",
    "#Finally, making a dictionalt to map these feature numbers to actual features:\n",
    "feat_dir={}\n",
    "i=0\n",
    "while i<len(num):\n",
    "    feat_dir[num[i]]=feat[i]\n",
    "    i=i+1\n",
    "\n",
    "for key in sorted(feat_dir):\n",
    "    print(\"feature \"+str(key)+\" -> \"+str(feat_dir[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressionModel (uid=dtr_37ae944ded4a) of depth 6 with 109 nodes\n",
      "  If (feature 12 in {0.0})\n",
      "   If (feature 4 in {1.0})\n",
      "    If (feature 19 in {1.0})\n",
      "     If (feature 9 in {0.0})\n",
      "      If (feature 1 <= 22.5)\n",
      "       If (feature 10 in {0.0})\n",
      "        Predict: 54.63495928454017\n",
      "       Else (feature 10 not in {0.0})\n",
      "        Predict: 67.7371818694598\n",
      "      Else (feature 1 > 22.5)\n",
      "       If (feature 1 <= 32.5)\n",
      "        Predict: 70.12158800435735\n",
      "       Else (feature 1 > 32.5)\n",
      "        Predict: 82.57053620624168\n",
      "     Else (feature 9 not in {0.0})\n",
      "      If (feature 0 <= 2003.5)\n",
      "       If (feature 14 in {1.0})\n",
      "        Predict: 61.40764018289706\n",
      "       Else (feature 14 not in {1.0})\n",
      "        Predict: 99.6894636984864\n",
      "      Else (feature 0 > 2003.5)\n",
      "       If (feature 1 <= 28.5)\n",
      "        Predict: 74.80824208516948\n",
      "       Else (feature 1 > 28.5)\n",
      "        Predict: 91.85999080433996\n",
      "    Else (feature 19 not in {1.0})\n",
      "     If (feature 3 in {0.0,4.0})\n",
      "      If (feature 1 <= 39.5)\n",
      "       If (feature 1 <= 38.5)\n",
      "        Predict: 89.50047970293059\n",
      "       Else (feature 1 > 38.5)\n",
      "        Predict: 162.7001941092769\n",
      "      Else (feature 1 > 39.5)\n",
      "       If (feature 8 in {0.0})\n",
      "        Predict: 74.57992577461523\n",
      "       Else (feature 8 not in {0.0})\n",
      "        Predict: 87.19006433174853\n",
      "     Else (feature 3 not in {0.0,4.0})\n",
      "      If (feature 2 in {1.0})\n",
      "       If (feature 0 <= 2005.5)\n",
      "        Predict: 70.93407507888607\n",
      "       Else (feature 0 > 2005.5)\n",
      "        Predict: 110.48150203111268\n",
      "      Else (feature 2 not in {1.0})\n",
      "       If (feature 0 <= 2003.5)\n",
      "        Predict: 102.39999183141771\n",
      "       Else (feature 0 > 2003.5)\n",
      "        Predict: 129.15292642062144\n",
      "   Else (feature 4 not in {1.0})\n",
      "    If (feature 10 in {0.0})\n",
      "     If (feature 18 in {0.0})\n",
      "      If (feature 3 in {0.0,4.0})\n",
      "       If (feature 7 in {1.0})\n",
      "        Predict: 81.4449885436633\n",
      "       Else (feature 7 not in {1.0})\n",
      "        Predict: 93.07813018035594\n",
      "      Else (feature 3 not in {0.0,4.0})\n",
      "       If (feature 1 <= 34.5)\n",
      "        Predict: 92.93700308514956\n",
      "       Else (feature 1 > 34.5)\n",
      "        Predict: 106.5376872939469\n",
      "     Else (feature 18 not in {0.0})\n",
      "      If (feature 2 in {1.0})\n",
      "       If (feature 11 in {0.0})\n",
      "        Predict: 98.66686409759622\n",
      "       Else (feature 11 not in {0.0})\n",
      "        Predict: 114.10793700507672\n",
      "      Else (feature 2 not in {1.0})\n",
      "       If (feature 3 in {0.0,4.0})\n",
      "        Predict: 108.51540700663078\n",
      "       Else (feature 3 not in {0.0,4.0})\n",
      "        Predict: 115.09982145472588\n",
      "    Else (feature 10 not in {0.0})\n",
      "     If (feature 15 in {1.0})\n",
      "      If (feature 6 in {1.0})\n",
      "       If (feature 0 <= 2006.5)\n",
      "        Predict: 122.11359998692642\n",
      "       Else (feature 0 > 2006.5)\n",
      "        Predict: 95.6189047567419\n",
      "      Else (feature 6 not in {1.0})\n",
      "       If (feature 0 <= 2005.5)\n",
      "        Predict: 122.1312803634945\n",
      "       Else (feature 0 > 2005.5)\n",
      "        Predict: 137.5702181941684\n",
      "     Else (feature 15 not in {1.0})\n",
      "      If (feature 1 <= 32.5)\n",
      "       If (feature 1 <= 26.5)\n",
      "        Predict: 102.67850599851151\n",
      "       Else (feature 1 > 26.5)\n",
      "        Predict: 116.53887409015321\n",
      "      Else (feature 1 > 32.5)\n",
      "       If (feature 1 <= 50.5)\n",
      "        Predict: 134.4671862889829\n",
      "       Else (feature 1 > 50.5)\n",
      "        Predict: 156.2178732985217\n",
      "  Else (feature 12 not in {0.0})\n",
      "   If (feature 13 in {0.0})\n",
      "    If (feature 1 <= 59.5)\n",
      "     If (feature 17 in {1.0})\n",
      "      If (feature 20 in {1.0})\n",
      "       Predict: 38.6059145209601\n",
      "      Else (feature 20 not in {1.0})\n",
      "       If (feature 14 in {0.0})\n",
      "        Predict: 83.5988525250788\n",
      "       Else (feature 14 not in {0.0})\n",
      "        Predict: 107.60120974932484\n",
      "     Else (feature 17 not in {1.0})\n",
      "      If (feature 8 in {0.0})\n",
      "       Predict: 103.91707406237668\n",
      "      Else (feature 8 not in {0.0})\n",
      "       If (feature 19 in {0.0})\n",
      "        Predict: 124.97598470336136\n",
      "       Else (feature 19 not in {0.0})\n",
      "        Predict: 182.0206209635121\n",
      "    Else (feature 1 > 59.5)\n",
      "     If (feature 8 in {1.0})\n",
      "      Predict: 176.989650489877\n",
      "     Else (feature 8 not in {1.0})\n",
      "      If (feature 14 in {0.0})\n",
      "       Predict: 127.901232979118\n",
      "      Else (feature 14 not in {0.0})\n",
      "       Predict: 267.901086855275\n",
      "   Else (feature 13 not in {0.0})\n",
      "    If (feature 1 <= 32.5)\n",
      "     If (feature 7 in {0.0})\n",
      "      If (feature 1 <= 31.5)\n",
      "       If (feature 0 <= 2004.5)\n",
      "        Predict: 98.20321332131823\n",
      "       Else (feature 0 > 2004.5)\n",
      "        Predict: 106.54206797281168\n",
      "      Else (feature 1 > 31.5)\n",
      "       Predict: 118.88435933988603\n",
      "     Else (feature 7 not in {0.0})\n",
      "      If (feature 0 <= 2008.5)\n",
      "       If (feature 16 in {1.0})\n",
      "        Predict: 97.4932940453934\n",
      "       Else (feature 16 not in {1.0})\n",
      "        Predict: 126.94957136493599\n",
      "      Else (feature 0 > 2008.5)\n",
      "       If (feature 1 <= 28.5)\n",
      "        Predict: 200.543262324662\n",
      "       Else (feature 1 > 28.5)\n",
      "        Predict: 114.47571329034697\n",
      "    Else (feature 1 > 32.5)\n",
      "     If (feature 0 <= 2006.5)\n",
      "      If (feature 5 in {0.0,1.0})\n",
      "       If (feature 7 in {2.0,4.0})\n",
      "        Predict: 112.38868761085011\n",
      "       Else (feature 7 not in {2.0,4.0})\n",
      "        Predict: 151.27563175618224\n",
      "      Else (feature 5 not in {0.0,1.0})\n",
      "       Predict: 192.4752167857207\n",
      "     Else (feature 0 > 2006.5)\n",
      "      If (feature 19 in {1.0})\n",
      "       If (feature 1 <= 47.5)\n",
      "        Predict: 135.37945867969637\n",
      "       Else (feature 1 > 47.5)\n",
      "        Predict: 115.62359207224674\n",
      "      Else (feature 19 not in {1.0})\n",
      "       If (feature 6 in {0.0})\n",
      "        Predict: 149.37120782632286\n",
      "       Else (feature 6 not in {0.0})\n",
      "        Predict: 203.54364579110603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the tree here\n",
    "print(example_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "639477f58c5b7ee916b3add4ad70c547",
     "grade": true,
     "grade_id": "cell-1c6f7a9628ad7949",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests for 10 points\n",
    "assert type(example_tree) == str\n",
    "assert 'DecisionTreeRegressionModel' in example_tree\n",
    "assert 'feature 0' in example_tree\n",
    "assert 'If' in example_tree\n",
    "assert 'Else' in example_tree\n",
    "assert 'Predict' in example_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5 pts)** Comment on the feature that is at the top of the tree. Does it make sense that that is the feature there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "30700e9cc5ca65ee007db0f0a2a2c447",
     "grade": true,
     "grade_id": "cell-8240c5a7db1c22af",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The illustration of 'example_tree\", that is the tree with index 3 (4th tree in the random forest model), shows me that the 'feature 12' is at the top of the tree. The dictionary I made earlier, that maps the feature number to the actual feature name from the dataframe, tells me that feature 12 is race_2.\\_Black; which is the dummy for race being black or not (1 if race is black, 0 if it is not). \n",
    "\n",
    "When I look back at the feature_importance dataframe, it shows that this particular feature is ranked 2nd on the basis of its importance in the random forest model with an importance value of 0.170570. The importance value in that dataframe is average of importance over all the trees in the model. In this particular tree, this feature is the most important feature, and it does make sense for this feature to be at the top of the tree. My argument is its importance value is pretty high so it makes sense to make a good split.\n",
    "\n",
    "P.S.: I have experienced that re-running the kernel and restarting the whole code will start at different starting points and thus everything changes, that is, the importance weights, the features having thos weights, the trees.\n",
    "This interpretation and answer is based upon the output that is a result of this execution instance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
