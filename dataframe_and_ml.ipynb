{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.ml import feature\n",
    "from pyspark.ml import regression\n",
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql import Row\n",
    "from pyspark import sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning: Use exclusively Spark. Do not use Pandas at all in this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Dataframes and Spark ML\n",
    "\n",
    "In this section, you will learn to create dataframes from messy data and then perform simple regression on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some mysterious process generating data, stored in `/datasets/host_server_requests`, with the following format:\n",
    "\n",
    "`feature1|feature2|...|featurem => outcome`\n",
    "\n",
    "`feature1` can be either \"HOST\" or \"SERVER\" and from feature $2$ through $m$ are floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_rdd = sc.textFile('/datasets/host_server_requests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "In this question, you will create a function `process_line` that receives a line from `/datasets/host_server_requests` and returns a `Row` object with the following columns: \n",
    "\n",
    "- You will codify the first feature as a column `f1` with a `1` if the source is `HOST` and `0` otherwise\n",
    "- You will create 7 other features that you assign to columns `f2`, `f3`, ..., through `f8`\n",
    "- Finally, you will assign the outcome to the column `label`\n",
    "- Remember to make all features of type `float`.\n",
    "\n",
    "For the following code:\n",
    "\n",
    "\n",
    "```python\n",
    "requests_rdd.map(process_line).take(10)\n",
    "```\n",
    "\n",
    "it should generate the following:\n",
    "\n",
    "```python\n",
    "[Row(f1=1.0, f2=2e-05, f3=0.80279, f4=-0.09174, f5=0.04041, f6=-0.22504, f7=-0.0504, f8=0.58149, label=163.877101489),\n",
    " Row(f1=1.0, f2=5e-05, f3=-0.00454, f4=-0.0211, f5=0.00174, f6=-0.11684, f7=0.19182, f8=-0.23745, label=-105.023368852),\n",
    " Row(f1=1.0, f2=0.00015, f3=-0.10437, f4=0.04869, f5=0.18333, f6=-0.21864, f7=0.27638, f8=-0.13441, label=-115.011801582),\n",
    " Row(f1=1.0, f2=-0.00015, f3=0.27118, f4=0.14526, f5=0.06101, f6=0.13401, f7=0.06237, f8=-0.74065, label=-122.623452696),\n",
    " Row(f1=1.0, f2=-6e-05, f3=0.1413, f4=0.12084, f5=0.05452, f6=0.09272, f7=0.2534, f8=-0.65331, label=-117.130523174),\n",
    " Row(f1=1.0, f2=-8e-05, f3=-0.41534, f4=-0.04205, f5=-0.00724, f6=-0.07463, f7=0.13273, f8=0.19112, label=-73.5775668047),\n",
    " Row(f1=1.0, f2=-8e-05, f3=-0.45937, f4=-0.23509, f5=-0.05679, f6=0.06077, f7=-0.49597, f8=-0.30668, label=-137.37933148),\n",
    " Row(f1=0.0, f2=2e-05, f3=-0.23465, f4=0.07345, f5=-0.07217, f6=-0.19256, f7=-0.14377, f8=-0.15183, label=-162.804738349),\n",
    " Row(f1=0.0, f2=-7e-05, f3=-0.10321, f4=0.27467, f5=0.04058, f6=-0.24541, f7=0.08631, f8=-0.2979, label=-212.111291232),\n",
    " Row(f1=1.0, f2=-7e-05, f3=-0.01039, f4=-0.00453, f5=-0.01352, f6=-0.05199, f7=-0.3772, f8=-0.19641, label=-91.5022329392)]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ae027852de73d98e3776430bff639156",
     "grade": false,
     "grade_id": "cell-244fd5f7c0138b60",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['SERVER'], ['0.00008'], ['0.45592'], ['0.25362'], ['-0.12878'], ['-0.06930'], ['-0.14740'], ['-0.53736', '-106.947151761']]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requests_rdd.take(1)[0]\n",
    "def process_line(st):\n",
    "    a=st.split(\"|\")\n",
    "    row_dir={}\n",
    "    i=0\n",
    "    while i<len(a):\n",
    "        k=\"f\"+str(i+1)\n",
    "        if i==0:\n",
    "            if a[i]==\"HOST\":\n",
    "                row_dir[k]=1.0\n",
    "            else:\n",
    "                row_dir[k]=0.0\n",
    "        else:\n",
    "            if \"=>\" in a[i]:\n",
    "                row_dir[k]=float(a[i].split(\" =>  \")[0])\n",
    "                row_dir[\"label\"]=float(a[i].split(\" =>  \")[1])\n",
    "            else:\n",
    "                row_dir[k]=float(a[i])\n",
    "        i=i+1\n",
    "    return Row(**row_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(f1=0.0, f2=8e-05, f3=0.45592, f4=0.25362, f5=-0.12878, f6=-0.0693, f7=-0.1474, f8=-0.53736, label=-106.947151761),\n",
       " Row(f1=0.0, f2=-1e-05, f3=0.10405, f4=-0.17047, f5=0.10127, f6=0.13776, f7=0.66619, f8=0.32221, label=127.061566761),\n",
       " Row(f1=1.0, f2=-1e-05, f3=-0.72394, f4=0.31161, f5=0.06975, f6=0.0086, f7=-0.44817, f8=-0.22976, label=-170.222653879),\n",
       " Row(f1=1.0, f2=0.00024, f3=-0.12887, f4=-0.01287, f5=0.18377, f6=-0.07004, f7=0.10632, f8=-0.40884, label=-127.850350049),\n",
       " Row(f1=1.0, f2=6e-05, f3=-0.06767, f4=0.08402, f5=0.14438, f6=-0.19704, f7=0.2839, f8=-0.12487, label=-110.295233798),\n",
       " Row(f1=1.0, f2=5e-05, f3=0.59406, f4=0.25195, f5=-0.00541, f6=-0.05218, f7=0.12202, f8=-0.1285, label=27.7039261796),\n",
       " Row(f1=0.0, f2=-8e-05, f3=-0.08562, f4=-0.00398, f5=-0.17124, f6=-0.13839, f7=-0.23696, f8=-0.814, label=-301.722572842),\n",
       " Row(f1=1.0, f2=-0.0001, f3=-0.28606, f4=-0.00447, f5=-0.10446, f6=-0.25006, f7=-0.03288, f8=-0.87445, label=-361.98704195),\n",
       " Row(f1=0.0, f2=-0.00018, f3=0.02462, f4=0.03503, f5=0.04794, f6=0.00395, f7=0.22638, f8=-0.39012, label=-158.114779137),\n",
       " Row(f1=1.0, f2=0.0001, f3=0.57047, f4=0.09443, f5=-0.0398, f6=-0.19704, f7=-0.36438, f8=-0.13402, label=-21.0376612977)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it here\n",
    "requests_rdd.map(process_line).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2fe0fd15181720aed141c4ccf80f4bbd",
     "grade": true,
     "grade_id": "cell-b4947d69e22e2f22",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(len(requests_rdd.map(process_line).first()), 9)\n",
    "np.testing.assert_equal(requests_rdd.map(process_line).count(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "Transform the `requests_rdd` RDD into a Spark 2.0 DataFrame and store it in `requests_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "887c47376104f469159443a9dbe2c2d9",
     "grade": false,
     "grade_id": "cell-b3baf345ff984885",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "requests_df=requests_rdd.map(process_line).toDF()\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1d0ecca803966f38a4c48122772e830e",
     "grade": true,
     "grade_id": "cell-333768d7c8281274",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(type(requests_df), sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(set(requests_df.columns), {'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'label'})\n",
    "np.testing.assert_equal(requests_df.count(), 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "\n",
    "In this question, we will explore the data. We have a hypothesis that depending on whether the request was from the \"HOST\" or \"SERVER\" (`f1` column), there are significant difference in the outcome (`label` column).\n",
    "\n",
    "You will find whether this is true by computing two quantities for each group of `f1`. You will compute the mean outcome and the *standard error of the mean* or SE of the outcome. The equation for SE of a variable $x$ is:\n",
    "\n",
    "$$\\text{SE}(x) = \\frac{\\text{std}(x)}{\\sqrt{n}}$$\n",
    "\n",
    "From `requests_df`, create a dataframe `summary_df` that contains, for each value of `f1`, the mean `label` as a column `mlabel` and the SEM of `label` as a column `semlabel`. For the SE equation, use the *sample standard devivation* computed by `fn.stddev_samp`. **Hint: perform an aggregate operation and use appropriate combinations of functions in the package `fn`. Rename columns appropriately**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f95851055354ab8dc2ec05ccf7c57ec9",
     "grade": false,
     "grade_id": "cell-15727d5a477764c8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------------------+\n",
      "| f1|             mlabel|          semlabel|\n",
      "+---+-------------------+------------------+\n",
      "|0.0|-29.611753412328927|1.7554606758419875|\n",
      "|1.0| -12.62243193686321|1.7481077347771363|\n",
      "+---+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "#Making a dataframe for the mean values for 0.0 and 1.0:\n",
    "mlbs=requests_df.groupBy(\"f1\").agg({\"label\":\"mean\"})\n",
    "mlbs=mlbs.withColumnRenamed(\"avg(label)\",\"mlabel\")\n",
    "\n",
    "#Making a dataframe for the standard deviation for 0.0 and 1.0:\n",
    "st=requests_df.groupBy(\"f1\").agg({\"label\":\"stddev_samp\"})\n",
    "\n",
    "#Number of instances for each category:\n",
    "nlbs=requests_df.groupBy(\"f1\").agg({\"label\":\"count\"})\n",
    "\n",
    "#Joining standard deviation and number of instances into a single dataframe and calcuating standard error in another column:\n",
    "sem=nlbs.join(st,\"f1\")\n",
    "sem=sem.withColumn(\"semlabel\",st[\"stddev_samp(label)\"]/fn.sqrt(nlbs[\"count(label)\"]))\n",
    "\n",
    "#Final join between mean and remaining values and dropping count and standard deviation:\n",
    "mlbs=mlbs.join(sem,\"f1\")\n",
    "summary_df=mlbs.drop(\"count(label)\",\"stddev_samp(label)\")\n",
    "summary_df.show(2)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of `summary_df` should look like:\n",
    "\n",
    "```python\n",
    "summary_df.printSchema()\n",
    "```\n",
    "```console\n",
    "root\n",
    " |-- f1: double (nullable = true)\n",
    " |-- mlabel: double (nullable = true)\n",
    " |-- semlabel: double (nullable = true)\n",
    "\n",
    "```\n",
    "The mean label for each `f1` feature should be:\n",
    "\n",
    "```python\n",
    "summary_df.select('f1', 'mlabel').show()\n",
    "```\n",
    "\n",
    "```console\n",
    "+---+------------------+\n",
    "| f1|            mlabel|\n",
    "+---+------------------+\n",
    "|0.0|-29.61175341232892|\n",
    "|1.0|-12.62243193686321|\n",
    "+---+------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "01274b653620c538a46bccfa72ef3b1c",
     "grade": true,
     "grade_id": "cell-0f48704616a8f55c",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "np.testing.assert_equal(summary_df.count(), 2)\n",
    "np.testing.assert_equal(set(summary_df.columns), {'f1', 'mlabel', 'semlabel'})\n",
    "np.testing.assert_approx_equal(summary_df.rdd.map(lambda r: r.mlabel).sum(), -42.23418534919213,\n",
    "                              significant=3)\n",
    "np.testing.assert_approx_equal(summary_df.rdd.map(lambda r: r.semlabel).sum(), 3.503568410619124,\n",
    "                              significant=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistically, we say that a mean $\\overline{x}$ is *statistically* different from another mean $\\overline{y}$ if it is not within 2 standard errors of the mean of x (i.e., $\\overline{y} \\not\\in \\{\\overline{x} \\pm 2\\text{SE}(x)\\}$). Discuss whether you think the mean label for f1 = 0 is statistically different from the mean label for f1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------------------+\n",
      "| f1|             mlabel|          semlabel|\n",
      "+---+-------------------+------------------+\n",
      "|0.0|-29.611753412328927|1.7554606758419875|\n",
      "|1.0| -12.62243193686321|1.7481077347771363|\n",
      "+---+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display it to make your argument\n",
    "summary_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 pts for your answer below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2 means are statiscally different.\n"
     ]
    }
   ],
   "source": [
    "mean_list=summary_df.select(\"mlabel\").collect()\n",
    "se_list=summary_df.select(\"semlabel\").collect()\n",
    "m_0=mean_list[0].mlabel   #Mean for 0.0\n",
    "m_1=mean_list[1].mlabel    #Mean for 1.0\n",
    "se_0=se_list[0].semlabel   #Standard error for 0.0\n",
    "se_1=se_list[1].semlabel   #Standard error for 1.0\n",
    "\n",
    "#Calcualting values at 2 standard deviations on both sides from the mean for 0.0:\n",
    "lower_lim_0_sd_2=m_0-2*se_0\n",
    "upper_lim_0_sd_2=m_0+2*se_0\n",
    "\n",
    "#Checking if the mean for 1.0 lies between the 2 standard deviations of the mean for 0.0 on either sides: \n",
    "if (m_1>=lower_lim_0_sd_2 and m_1<=upper_lim_0_sd_2):\n",
    "    print(\"The 2 means are not statistically different.\")\n",
    "else:\n",
    "    print(\"The 2 means are statiscally different.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "47b519124f162219100057c7b90984ba",
     "grade": true,
     "grade_id": "cell-55c3ae319a99bc6c",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The 2 means are statistically different based on the code above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "\n",
    "Use the transformer `VectorAssembler` to create a dataframe that puts all columns `f1`, `f2`, ..., `f8` from `requests_df` into a column named `features`. Assign the vector assembler object into a variable `va` and the new dataframe into the variable  `features_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9b8e718f4d06bf724fb9be5673a5ad75",
     "grade": false,
     "grade_id": "cell-56d045d1b2c78b89",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "cols=[]\n",
    "for col in requests_df.columns:\n",
    "    if \"f\" in col:\n",
    "        cols.append(col)\n",
    "va=feature.VectorAssembler(inputCols=cols,outputCol=\"features\")\n",
    "features_df=va.transform(requests_df)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of the new dataframe should be like this:\n",
    "\n",
    "```python\n",
    "features_df.printSchema()\n",
    "```\n",
    "\n",
    "```console\n",
    "root\n",
    " |-- f1: double (nullable = true)\n",
    " |-- f2: double (nullable = true)\n",
    " |-- f3: double (nullable = true)\n",
    " |-- f4: double (nullable = true)\n",
    " |-- f5: double (nullable = true)\n",
    " |-- f6: double (nullable = true)\n",
    " |-- f7: double (nullable = true)\n",
    " |-- f8: double (nullable = true)\n",
    " |-- label: double (nullable = true)\n",
    " |-- features: vector (nullable = true)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+--------+--------+-------+--------+--------+--------------+--------------------+\n",
      "| f1|     f2|      f3|      f4|      f5|     f6|      f7|      f8|         label|            features|\n",
      "+---+-------+--------+--------+--------+-------+--------+--------+--------------+--------------------+\n",
      "|0.0| 8.0E-5| 0.45592| 0.25362|-0.12878|-0.0693| -0.1474|-0.53736|-106.947151761|[0.0,8.0E-5,0.455...|\n",
      "|0.0|-1.0E-5| 0.10405|-0.17047| 0.10127|0.13776| 0.66619| 0.32221| 127.061566761|[0.0,-1.0E-5,0.10...|\n",
      "|1.0|-1.0E-5|-0.72394| 0.31161| 0.06975| 0.0086|-0.44817|-0.22976|-170.222653879|[1.0,-1.0E-5,-0.7...|\n",
      "+---+-------+--------+--------+--------+-------+--------+--------+--------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try it here\n",
    "features_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f41db05c38db0e4e7325099be89cd82",
     "grade": true,
     "grade_id": "cell-505b09bb3262a7ad",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_equal(type(features_df), sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(set(features_df.columns), \n",
    "                        {'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'features', 'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5:\n",
    "\n",
    "Run a linear regression model on `features_df` using the `features` column to predict the `label` column. Store the transformer fit to the data in the `lr_model` variable (the transformer is what the estimator's `fit` function returns). Use the transformer to create a dataframe named `predictions_df` with two columns: `label` and `prediction` based on the `features_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bf7c8c1d895958b567e5aae92cf6a2e0",
     "grade": false,
     "grade_id": "cell-73fa24e4562cc788",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [17.625919361532464,166414.78271509538,141.90187235799473,0.0,0.0,358.677012519037,0.0,228.07655342226417]\n",
      "Intercept: -28.78029963178382\n",
      "+--------------+-------------------+\n",
      "|         label|         prediction|\n",
      "+--------------+-------------------+\n",
      "|-106.947151761| -98.18674908367636|\n",
      "| 127.061566761| 107.22033388272486|\n",
      "|-170.222653879|-164.86521617888468|\n",
      "|-127.850350049|-107.87028276739508|\n",
      "|-110.295233798| -109.9256307824003|\n",
      "+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "lr=regression.LinearRegression(featuresCol=\"features\",labelCol=\"label\",maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model=lr.fit(features_df)\n",
    "print(\"Coefficients: \"+str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))\n",
    "\n",
    "predictions_df=lr_model.transform(features_df)\n",
    "predictions_df=predictions_df.select(\"label\",\"prediction\")\n",
    "predictions_df.show(5)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataframe should be in `predictions_df`. Running `predictions_df.show(5)` should produce something like\n",
    "\n",
    "```python\n",
    "predictions_df.show(5)\n",
    "```\n",
    "\n",
    "```console\n",
    "+--------------+-------------------+\n",
    "|         label|         prediction|\n",
    "+--------------+-------------------+\n",
    "| 163.877101489| 159.06994708337518|\n",
    "|-105.023368852| -99.52598722329135|\n",
    "|-115.011801582|-109.91382979074436|\n",
    "|-122.623452696|-118.62864861627764|\n",
    "|-117.130523174|-116.89245751669506|\n",
    "+--------------+-------------------+\n",
    "only showing top 5 rows\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "17142a6e7131d10366b0dc029fdf1b1e",
     "grade": true,
     "grade_id": "cell-966429bd3d48aa0a",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts:\n",
    "np.testing.assert_equal(set(predictions_df.columns), {'label', 'prediction'})\n",
    "np.testing.assert_equal(predictions_df.count(), 10000)\n",
    "np.testing.assert_equal(type(lr_model), regression.LinearRegressionModel)\n",
    "np.testing.assert_equal(type(va), feature.VectorAssembler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root mean squared error is defined as\n",
    "\n",
    "$$ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2}$$\n",
    "\n",
    "Combine functions in `fn` package and other functions to create a dataframe called `rmse_df` that contains the root mean squared error in column `rmse` based on the `predictions_df` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "33a4b6cd52e592b1234d54a918a0550c",
     "grade": false,
     "grade_id": "cell-926f142075117a76",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.538945505198058|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "#Creating a dataframe with the residual error terms:\n",
    "rms=predictions_df.withColumn(\"e\",(predictions_df[\"prediction\"]-predictions_df[\"label\"]))\n",
    "\n",
    "#Adding a column for the square of the residual terms:\n",
    "rms=rms.withColumn(\"sq_e\",(rms[\"e\"]**2))\n",
    "\n",
    "#Creating a new dataframe and aggregating to add all the squared residual terms:\n",
    "rmse_df=rms.groupBy().agg({\"sq_e\":\"sum\"})\n",
    "\n",
    "#Calculating the total number of elements:\n",
    "n=rms.groupBy().agg({\"e\":\"count\"}).collect()[0][0]\n",
    "\n",
    "#Dividing the aggregated squared residual terms and dividing them with the total number of terms and then square root(RMSE):\n",
    "rmse_df=rmse_df.withColumn(\"rmse\",fn.sqrt((1/n * rmse_df[\"sum(sq_e)\"])))\n",
    "\n",
    "#Finally, dropping unwanted columns:\n",
    "rmse_df=rmse_df.drop(\"sum(sq_e)\")\n",
    "rmse_df.show(1)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cab72e6d6c675bca35428c189508d683",
     "grade": true,
     "grade_id": "cell-ce1df3212ea78b19",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "np.testing.assert_array_less(rmse_df.first().rmse, 10)\n",
    "np.testing.assert_equal(rmse_df.count(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Add the constant 10 to each feature in `requests_df` and redo the analytics pipeline from Q5, creating a vector assembler `va2`, `features2_df`, `lr_model2`, and `predictions2_df`. When adding the constant 10, preserve the column names in `features2_df` such that the columns in this new dataframe should be `f1` thorugh `f8`. Do not modify the column `label`. Fit a new linear model, similar to question 4, compute its root mean square error, and store it in `rmse2_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "af7de031344a62e47f17d42fd9512ba6",
     "grade": false,
     "grade_id": "cell-41b0350bc300afd9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [17.625913988313656,166411.82306045984,141.9018882088414,0.0,0.0,358.67701606012173,0.0,228.07654583016975]\n",
      "Intercept: -1671609.8245451555\n",
      "+--------------+-------------------+\n",
      "|         label|         prediction|\n",
      "+--------------+-------------------+\n",
      "|-106.947151761| -98.18697484582663|\n",
      "| 127.061566761| 107.22036311915144|\n",
      "|-170.222653879| -164.8652017065324|\n",
      "|-127.850350049|-107.87099769548513|\n",
      "|-110.295233798|-109.92581460834481|\n",
      "+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.538955501612891|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "requests_df2=requests_df.select(requests_df['f1']+10,requests_df['f2']+10,requests_df['f3']+10,requests_df['f4']+10,requests_df['f5']+10,requests_df['f6']+10,requests_df['f7']+10,requests_df['f8']+10,requests_df[\"label\"])\n",
    "cols2=[\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"label\"]\n",
    "rq2=requests_df2.toDF(*cols2)\n",
    "\n",
    "cols_2=[]\n",
    "for col2 in rq2.columns:\n",
    "    if \"f\" in col2:\n",
    "        cols_2.append(col2)\n",
    "va2=feature.VectorAssembler(inputCols=cols_2,outputCol=\"features\")\n",
    "features2_df=va2.transform(rq2)\n",
    "\n",
    "lr2=regression.LinearRegression(featuresCol=\"features\",labelCol=\"label\",maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model2=lr2.fit(features2_df)\n",
    "print(\"Coefficients: \"+str(lr_model2.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model2.intercept))\n",
    "\n",
    "predictions2_df=lr_model2.transform(features2_df)\n",
    "predictions2_df=predictions2_df.select(\"label\",\"prediction\")\n",
    "predictions2_df.show(5)\n",
    "\n",
    "rms2=predictions2_df.withColumn(\"e\",(predictions2_df[\"prediction\"]-predictions2_df[\"label\"]))\n",
    "rms2=rms2.withColumn(\"sq_e\",(rms2[\"e\"]**2))\n",
    "rmse2_df=rms2.groupBy().agg({\"sq_e\":\"sum\"})\n",
    "n2=rms2.groupBy().agg({\"e\":\"count\"}).collect()[0][0]\n",
    "rmse2_df=rmse2_df.withColumn(\"rmse\",fn.sqrt((1/n * rmse2_df[\"sum(sq_e)\"])))\n",
    "rmse2_df=rmse2_df.drop(\"sum(sq_e)\")\n",
    "rmse2_df.show(1)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c26d79182d21ff9debc8f3c25934d7f8",
     "grade": true,
     "grade_id": "cell-978de063c691abb7",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts:\n",
    "np.testing.assert_equal(set(predictions2_df.columns), {'label', 'prediction'})\n",
    "np.testing.assert_equal(predictions2_df.count(), 10000)\n",
    "np.testing.assert_equal(type(va2), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(lr_model2), regression.LinearRegressionModel)\n",
    "np.testing.assert_array_less(rmse2_df.first().rmse, 10)\n",
    "np.testing.assert_equal(rmse2_df.count(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the root mean squared error of Q5 and Q6. They should be almost exactly the same. Also, compare the coefficients and intercepts of `lr_model` and `lr_model2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Q5\n",
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.538945505198058|\n",
      "+-----------------+\n",
      "\n",
      "RMSE Q6\n",
      "+-----------------+\n",
      "|             rmse|\n",
      "+-----------------+\n",
      "|8.538955501612891|\n",
      "+-----------------+\n",
      "\n",
      "intercept lr_model -28.78029963178382\n",
      "intercept lr_model2 -1671609.8245451555\n",
      "coefficients lr_model [17.625919361532464,166414.78271509538,141.90187235799473,0.0,0.0,358.677012519037,0.0,228.07655342226417]\n",
      "coefficients lr_model2 [17.625913988313656,166411.82306045984,141.9018882088414,0.0,0.0,358.67701606012173,0.0,228.07654583016975]\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE Q5\")\n",
    "rmse_df.show()\n",
    "print(\"RMSE Q6\")\n",
    "rmse2_df.show()\n",
    "print(\"intercept lr_model\", lr_model.intercept)\n",
    "print(\"intercept lr_model2\", lr_model2.intercept)\n",
    "print(\"coefficients lr_model\", lr_model.coefficients)\n",
    "print(\"coefficients lr_model2\", lr_model2.coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 pts for your answer below:** Comment on why there are differences or similarities between coefficients, intercepts, RMSE, even though we modified the features. You can use [Latex in Markdown](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html#LaTeX-equations) to put some math into your explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cd5984ba2cba0e00d13e96234557af17",
     "grade": true,
     "grade_id": "cell-29b2a054968a563c",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Q5:**\n",
    "\n",
    "**Coefficients: [17.625919361532464,166414.78271509538,141.90187235799473,0.0,0.0,358.677012519037,0.0,228.07655342226417]**\n",
    "\n",
    "**Intercept: -28.78029963178382**\n",
    "\n",
    "**RMSE: 8.538945505198058**\n",
    "\n",
    "\n",
    "**Q6:**\n",
    "\n",
    "**Coefficients: [17.625913988313656,166411.82306045984,141.9018882088414,0.0,0.0,358.67701606012173,0.0,228.07654583016975]**\n",
    "\n",
    "**Intercept: -1671609.8245451555**\n",
    "\n",
    "**RMSE: 8.538955501612891**\n",
    "\n",
    "The change in the coefficients isn't that big; the minute change is the result of addition of the noise (+10) to every column. The intercept, however, has changed drastically (went from -28.78029963178382 to -1671609.8245451555). This change is the reflection of the the noise term getting multiplied by the coefficients and aggregating to the increase in slope. RMSE has a very minute change because the models fit almost identically, as the residual error terms won't change much."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
